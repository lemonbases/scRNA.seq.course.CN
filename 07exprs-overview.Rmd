---
output: html_document
---
# 表达矩阵质控 {#cleaning-the-expression-matrix}

## UMI表达质控 {#exprs-qc}

### 介绍

基因表达定量后整理为**表达矩阵**文件，其中每行对应基因(转录本)，每列对应单个细胞。检查矩阵去除read QC或mapping QC中低质量细胞，否则会引入技术噪音，模糊下游感兴趣的生物信号。

目前没有通用的scRNA-seq标准化方法，下文中不同质控期望值因不同实验差异很大。因此，质控时，通过比较数据集内部找到异常细胞，而不是独立的质控标准。当比较不同protocol的数据集的质控指标时，应格外注意。

### Tung数据集

使用芝加哥大学[Yoav Gilad](http://giladlab.uchicago.edu/)实验室三个不同个体诱导多能干细胞[数据集](http://jdblischak.github.io/singleCellSeq/analysis/) [@Tung2017-ba]。细胞分选采用Fluidigm C1平台，同时使用UMI和ERCC **spike-in**，数据文件位于工作目录下的`tung`文件夹中，这些文件15/03/16创建原始文件的拷贝。

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center')
```

```{r, message=FALSE, warning=FALSE}
library(SingleCellExperiment)
library(scater)
options(stringsAsFactors = FALSE)
```

导入数据和注释:
```{r}
molecules <- read.table("data/tung/molecules.txt", sep = "\t")
anno <- read.table("data/tung/annotation.txt", sep = "\t", header = TRUE)
```

查看表达矩阵
```{r}
head(molecules[ , 1:3])
head(anno)
```

数据包括 `r length(unique(anno$individual))` 个个体，3次`r length(unique(anno$replicate))` 重复，共 `r length(unique(anno$batch))` 个批次.

使用`SingleCellExperiment` (SCE)和`scater`标准化分析。首先创建SCE对象：

```{r}
umi <- SingleCellExperiment(
    assays = list(counts = as.matrix(molecules)), 
    colData = anno
)
```

移除在任何细胞都不表达的基因:
```{r}
keep_feature <- rowSums(counts(umi) > 0) > 0
umi <- umi[keep_feature, ]
```

定义control特征(基因) - ERCC spike-ins 和线粒体基因，(作者[提供](http://jdblischak.github.io/singleCellSeq/analysis/qc-filter-ipsc.html)):
```{r}
isSpike(umi, "ERCC") <- grepl("^ERCC-", rownames(umi))
isSpike(umi, "MT") <- rownames(umi) %in% 
    c("ENSG00000198899", "ENSG00000198727", "ENSG00000198888",
    "ENSG00000198886", "ENSG00000212907", "ENSG00000198786",
    "ENSG00000198695", "ENSG00000198712", "ENSG00000198804",
    "ENSG00000198763", "ENSG00000228253", "ENSG00000198938",
    "ENSG00000198840")
```

计算质量指标:
```{r,warning=FALSE}
umi <- calculateQCMetrics(
    umi,
    feature_controls = list(
        ERCC = isSpike(umi, "ERCC"), 
        MT = isSpike(umi, "MT")
    )
)
```


### 细胞质控

#### 文库大小

查看每个样本检测的总RNA分子数，read counts 或 UMI counts。如果样本中reads/分子数太少，可能细胞破损或捕获失败，应该移除该样本。

```{r total-counts-hist, fig.cap = "Histogram of library sizes for all cells"}
hist(
    umi$total_counts,
    breaks = 100
)
abline(v = 25000, col = "red")
```

**练习1**

1. 过滤移除多少细胞？

2. 每个细胞总分子数应该服从什么分布？

**答案**

```{r}
filter_by_total_counts <- (umi$total_counts > 25000)
table(filter_by_total_counts)
```

#### 检测基因数

除了确保每个样品的足够测序深度外，还希望确保读数均衡分布在转录组中。 因此，计算每个样品中检测到的基因数。

```{r total-features-hist, fig.cap = "Histogram of the number of detected genes in all cells"}
hist(
    umi$total_features_by_counts,
    breaks = 100
)
abline(v = 7000, col = "red")
```

从上图可以看出大多数细胞检测到7,000-10,000个基因，这对高深度scRAN-seq是正常的。然而，受实验protocol和测序深度的影响。比如基于droplet的方法或样品测序深度低时每个细胞检测基因要少。上图最明显的特征是左侧**拖尾**严重，如果细胞间检测率相同，应该服从正态分布。因此移除分布在左侧尾部的数据(检测少于7000基因的细胞)

**联系2**

上述过滤了多少细胞？

**答案**

```{r}
filter_by_expr_features <- (umi$total_features_by_counts > 7000)
table(filter_by_expr_features)
```

#### ERCCs和MTs

细胞质量的另一个衡量标准是ERCC **spike-in** RNA和内源RNA之间的比值。其可用于估计细胞中捕获RNA的总量。 如果**spike-in** RNA较高，表明细胞内源RNA总量低，可能是由于细胞死亡或受到应激导致RNA降解。
Cells with a high level of _spike-in_ RNAs
had low starting amounts of RNA, likely due to the cell being
dead or stressed which may result in the RNA being degraded.

```{r mt-vs-counts, fig.cap = "Percentage of counts in MT genes"}
plotColData(
    umi,
    x = "total_features_by_counts",
    y = "pct_counts_MT",
    colour = "batch"
)
```

```{r ercc-vs-counts, fig.cap = "Percentage of counts in ERCCs"}
plotColData(
    umi,
    x = "total_features_by_counts",
    y = "pct_counts_ERCC",
    colour = "batch"
)
```

上述分析表明，来自NA19098.r2批次的大多数细胞具有非常高的ERCC / Endo 比。作者已经解释该批次包含较小尺寸的细胞。


**练习3**

移除NA19098.r2批次以及移除高表达线粒体基因的细胞(> 10%细胞总计数)

__Our answer__

```{r}
filter_by_ERCC <- umi$batch != "NA19098.r2"
table(filter_by_ERCC)
filter_by_MT <- umi$pct_counts_MT < 10
table(filter_by_MT)
```

**练习4**

如果研究数据集细胞大小不同(比如正常和衰老细胞)，ERCC和counts比例会是什么分布？

**答案**

小的细胞(正常细胞)比大的细胞(衰老细胞)具有更高的ERCC/counts比。

### 细胞过滤

#### 手动过滤

根据之前分析定义细胞过滤器：

```{r}
umi$use <- (
    # sufficient features (genes)
    filter_by_expr_features &
    # sufficient molecules counted
    filter_by_total_counts &
    # sufficient endogenous RNA
    filter_by_ERCC &
    # remove cells with unusual number of reads in MT genes
    filter_by_MT
)
```

```{r}
table(umi$use)
```

#### 自动过滤

`scater`提供根据质控数据进行PCA自动筛选异常细胞的方法。默认情况下，下列统计量用于基于PCA的异常细胞检测：

* **pct_counts_top_100_features**
* **total_features**
* **pct_counts_feature_controls**
* **n_detected_feature_controls**
* **log10_counts_endogenous_features**
* **log10_counts_feature_controls**

`scater`首先创建一个行为细胞，列为不同QC统计值的矩阵，然后通过`mvoutlier`包筛选QC统计值与其它细胞显著不同的异常细胞，可能对应低质量细胞。通过PCA画图可视化异常细胞：

```{r auto-cell-filt, fig.align='center', fig.cap="PCA plot used for automatic detection of cell outliers", message=FALSE, warning=FALSE, out.width='90%'}
umi <- runPCA(
    umi, 
    use_coldata = TRUE, 
    detect_outliers = TRUE
)
reducedDimNames(umi)
```

结果存储于umi的`$outlier`，其标识细胞是否为异常细胞。自动异常细胞检测提供丰富的信息，但是推荐特异性手动检测过滤数据集。

```{r}
table(umi$outlier)
```

通过PCA查看细胞质量分布

```{r}
plotReducedDim(
    umi,
    use_dimred = "PCA_coldata",
    size_by = "total_features_by_counts", 
    shape_by = "use", 
    colour_by = "outlier"
)
```

### 手工过滤和自动过滤比较

**练习5**

用Venn图显示自动和手工筛选的异常细胞

**提示**：使用[limma](https://bioconductor.org/packages/release/bioc/html/limma.html)中`vennCounts`和`vennDiagram`函数绘制Venn图。

**答案**

```{r cell-filt-comp, fig.cap = "Comparison of the default, automatic and manual cell filters", warning=FALSE}
library(limma)
auto <- colnames(umi)[umi$outlier]
man <- colnames(umi)[!umi$use]
venn.diag <- vennCounts(
    cbind(colnames(umi) %in% auto,
    colnames(umi) %in% man)
)
vennDiagram(
    venn.diag,
    names = c("Automatic", "Manual"),
    circle.col = c("blue", "green")
)
```

### 基因分析

#### 基因表达

除了移除低质量细胞外，通常也移除受技术误差影响较大的基因。而且查看基因表达谱可以帮助改进实验步骤。

查看Top50表达基因占reads的比例
```{r eval=FALSE}
plotHighestExprs(umi, exprs_values = "counts")
```
```{r top50-gene-expr-1, fig.cap = "Number of total counts consumed by the top 50 expressed genes", fig.asp = 1,echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-qc_files/figure-html/top50-gene-expr-1.png")
```
Top50表达的基因reads分布相对平缓，表明(但不保证)细胞的转录组覆盖较好。然而在Top15基因中含有spike-ins，表明如果重复实验，稀释spike-in的浓度较好。

#### 基因过滤

通常建议移除表达水平低，被认为是**未检测出的**基因。UMI数据中基因**detectable**定义为至少在两个细胞中包含至少1个基因的转录本。read counts数据，基因**detectable**定义为至少在2个细胞检测到至少5个read比对到该基因上。然而，在两种情况下阈值很大程度上取决于测序深度。另外，基因过滤需在细胞过滤之后，因为一些基因可能只在低质量细胞中检测到。（**注意** `colData(umi)$use`应用于`umi`数据集）。

```{r}
keep_feature <- nexprs(
  umi[,colData(umi)$use], 
  byrow = TRUE, 
  detection_limit = 1
) >= 2
rowData(umi)$use <- keep_feature
```

```{r}
table(keep_feature)
```

根据细胞类型，实验protocol，测序深度，其它阈值可能也合适。

### 保存数据

质控后数据集的维度(注意上述运用的基因过滤)：
```{r}
dim(umi[rowData(umi)$use, colData(umi)$use])
```

创建log变换的counts值(下面章节用到)，从`reducedDim`移除保存的PCA结果：
```{r,eval=FALSE}
assay(umi, "logcounts_raw") <- log2(counts(umi) + 1)
reducedDim(umi) <- NULL
```

保存数据:
```{r,eval=FALSE}
saveRDS(umi, file = "data/tung/umi.rds")
```

### 大作业

使用相同的Blischak数据完成质控分析，使用`tung/reads.txt`文件读入reads，完成后将结果和我们进行对比(下一章)。


## Reads表达质控

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center')
```

```{r, message=FALSE, warning=FALSE}
library(SingleCellExperiment)
library(scater)
options(stringsAsFactors = FALSE)
```

```{r}
reads <- read.table("data/tung/reads.txt", sep = "\t")
anno <- read.table("data/tung/annotation.txt", sep = "\t", header = TRUE)
```

```{r}
head(reads[ , 1:3])
head(anno)
```

```{r}
reads <- SingleCellExperiment(
    assays = list(counts = as.matrix(reads)), 
    colData = anno
)
```

```{r}
keep_feature <- rowSums(counts(reads) > 0) > 0
reads <- reads[keep_feature, ]
```

```{r}
isSpike(reads, "ERCC") <- grepl("^ERCC-", rownames(reads))
isSpike(reads, "MT") <- rownames(reads) %in% 
    c("ENSG00000198899", "ENSG00000198727", "ENSG00000198888",
    "ENSG00000198886", "ENSG00000212907", "ENSG00000198786",
    "ENSG00000198695", "ENSG00000198712", "ENSG00000198804",
    "ENSG00000198763", "ENSG00000228253", "ENSG00000198938",
    "ENSG00000198840")
```

```{r,warning=FALSE}
reads <- calculateQCMetrics(
    reads,
    feature_controls = list(
        ERCC = isSpike(reads, "ERCC"), 
        MT = isSpike(reads, "MT")
    )
)
```

```{r total-counts-hist-reads, fig.cap = "Histogram of library sizes for all cells"}
hist(
    reads$total_counts,
    breaks = 100
)
abline(v = 1.3e6, col = "red")
```

```{r}
filter_by_total_counts <- (reads$total_counts > 1.3e6)
table(filter_by_total_counts)
```

```{r total-features-hist-reads, fig.cap = "Histogram of the number of detected genes in all cells"}
hist(
    reads$total_features_by_counts,
    breaks = 100
)
abline(v = 7000, col = "red")
```

```{r}
filter_by_expr_features <- (reads$total_features_by_counts > 7000)
table(filter_by_expr_features)
```

```{r mt-vs-counts-reads, fig.cap = "Percentage of counts in MT genes"}
plotColData(
    reads,
    x = "total_features_by_counts",
    y = "pct_counts_MT",
    colour = "batch"
)
```

```{r ercc-vs-counts-reads, fig.cap = "Percentage of counts in ERCCs"}
plotColData(
    reads,
    x = "total_features_by_counts",
    y = "pct_counts_ERCC",
    colour = "batch"
)
```

```{r}
filter_by_ERCC <- 
    reads$batch != "NA19098.r2" & reads$pct_counts_ERCC < 25
table(filter_by_ERCC)
filter_by_MT <- reads$pct_counts_MT < 30
table(filter_by_MT)
```

```{r}
reads$use <- (
    # sufficient features (genes)
    filter_by_expr_features &
    # sufficient molecules counted
    filter_by_total_counts &
    # sufficient endogenous RNA
    filter_by_ERCC &
    # remove cells with unusual number of reads in MT genes
    filter_by_MT
)
```

```{r}
table(reads$use)
```

```{r auto-cell-filt-reads, fig.align='center', fig.cap="PCA plot used for automatic detection of cell outliers", message=FALSE, warning=FALSE, out.width='90%'}
reads <- runPCA(
    reads,
    use_coldata = TRUE, 
    detect_outliers = TRUE
)
reducedDimNames(reads)
```

```{r}
table(reads$outlier)
```

```{r}
plotReducedDim(
    reads,
    use_dimred = "PCA_coldata",
    size_by = "total_features_by_counts", 
    shape_by = "use", 
    colour_by = "outlier"
)
```

```{r cell-filt-comp-reads, fig.cap = "Comparison of the default, automatic and manual cell filters"}
library(limma)
auto <- colnames(reads)[reads$outlier]
man <- colnames(reads)[!reads$use]
venn.diag <- vennCounts(
    cbind(colnames(reads) %in% auto,
    colnames(reads) %in% man)
)
vennDiagram(
    venn.diag,
    names = c("Automatic", "Manual"),
    circle.col = c("blue", "green")
)
```

```{r eval=FALSE} 
plotHighestExprs(reads, exprs_values = "counts")
```

```{r top50-gene-expr-reads, fig.cap = "Number of total counts consumed by the top 50 expressed genes", fig.asp = 1,echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-qc-reads_files/figure-html/top50-gene-expr-reads-1.png")
```

```{r}
keep_feature <- nexprs(
  reads[,colData(reads)$use], 
  byrow = TRUE, 
  detection_limit = 1
) >= 2
rowData(reads)$use <- keep_feature
```

```{r}
table(keep_feature)
```

```{r}
dim(reads[rowData(reads)$use, colData(reads)$use])
```

```{r,eval=FALSE,echo=TRUE}
assay(reads, "logcounts_raw") <- log2(counts(reads) + 1)
reducedDim(reads) <- NULL
```

```{r,eval=FALSE,echo=TRUE}
saveRDS(reads, file = "data/tung/reads.rds")
```

通过比对图\@ref(fig:cell-filt-comp) 和 图\@ref(fig:cell-filt-comp-reads)发现，基于reads过滤比对基于UMI的分析去除了更多的细胞。如果返回比较结果，应该得出结论ERCC和MT过滤对基于reads的分析更严格。

## 数据可视化

### 介绍

本章继续使用之前章节产生的过滤后`Tung`数据集，我们将使用几种数据可视化方式，以便评估质量控制后表达矩阵的改变。`scater`包提供了几种有用的函数来简化可视化。

scRNA-sq分析的一个重要方面是控制批次效应。批次效应是实验过程中引入的技术偏差。比如，不同实验室准备的样品或同一实验室不同时间准备的样品，同一批处理的数据相似度更高。最差的情况，批次效应可能被[误认为](http://f1000research.com/articles/4-121/v1) 真实的生物差异。`Tung`数据详细记录样品处理过程，允许探索批次效应问题。理想情况下，同一个体细胞聚集在一起，不同group对应每个个体，这说明存在批次效应。

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center')
```

```{r, message=FALSE, warning=FALSE}
library(SingleCellExperiment)
library(scater)
options(stringsAsFactors = FALSE)
umi <- readRDS("data/tung/umi.rds")
umi.qc <- umi[rowData(umi)$use, colData(umi)$use]
endog_genes <- !rowData(umi.qc)$is_feature_control
```

### PCA plot {#visual-pca}

查看数据分布的最简单方式是主成分分析，然后查看前两个主成分。

[主成分分析(PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) 是一种统计方法，使用正交变换将观察变量转化为一组线性无关的变量，称之为主成分。主成分的个数少于或等于原始变量数。

数学上，主成分对应协方差矩阵的特征向量，特征向量按照特征值进行排序，使得第一主成分解释最大的数据变异，后续主成分在与前面主成分正交的约下具有最高的方差。(图片来自[这里](http://www.nlpca.org/pca_principal_component_analysis.html))。

```{r clust-pca, echo=FALSE, fig.cap="Schematic representation of PCA dimensionality reduction", out.width='100%'}
knitr::include_graphics("figures/pca.png")
```

#### Before QC

对数变换前:
```{r eval=FALSE}
tmp <- runPCA(
  umi[endog_genes, ],
  exprs_values = "counts"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-before-qc1, fig.cap = "PCA plot of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-pca-before-qc1-1.png")
```

对数变换后:
```{r eval=FALSE}
tmp <- runPCA(
  umi[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-before-qc2, fig.cap = "PCA plot of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-pca-before-qc2-1.png")
```

显然，对数变换更适合我们的数据，其减少了第一组成分的变异，分离出一些生物效应。而且使表达数据的分布更符合正态分布，后续分析和章节中我们默认使用log变换的counts数据。

**然而，仅仅对数变换不足以解释细胞间不同计算因子(如测序深度)带来的差异。因此，下游分析中不要使用`logcounts_raw`，而是使用`SingleCellExperiment`对象的`logcounts`,其不仅仅对数变换，而且根据文库大小进行标准化(比如CPM标准化)。本课程中我们仅使用`logcounts_raw`进行演示！**

#### 质控后

```{r eval=FALSE}
tmp <- runPCA(
  umi.qc[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-after-qc, fig.cap = "PCA plot of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-pca-after-qc-1.png")

```

比较图 \@ref(fig:expr-overview-pca-before-qc2) 和图 \@ref(fig:expr-overview-pca-after-qc), 发现质控后NA19098.r2不再是离群组。

默认情况下，scater使用500个变化最大的基因进行PCA分析，可以通过`ntop`参数进行修改。

**练习1**
如果使用所有的14066基因，PCA图会如何？只是用50个基因呢？为什么第一主成分解释整体变异差别那么大？

**提示** 使用`plotPCA`函数中`ntop`参数

**答案**

```{r eval=FALSE,echo=TRUE}
tmp <- runPCA(
    umi.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    ntop = 14066
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-after-qc-exercise1-1, fig.cap = "PCA plot of the tung data (14214 genes)",echo=FALSE}
knitr::include_graphics("https://lemonbases.github.io/scRNA.seq.course.CN/07exprs-overview_files/figure-html/expr-overview-pca-after-qc-exercise1-1-1.png")
```
```{r eval=FALSE,echo=TRUE}
tmp <- runPCA(
    umi.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    ntop = 50
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-after-qc-exercise1-2, fig.cap = "PCA plot of the tung data (50 genes)",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-pca-after-qc-exercise1-2-1.png")
```

### tSNE可视化 {#visual-tsne}

scRNA-seq数据可视化另一个常用方法是tSNE。tSNE](https://lvdmaaten.github.io/tsne/) (t-Distributed Stochastic Neighbor Embedding)整合降维(比如PCA)和最近邻网络随机游走在保持细胞间局部距离的基础上，将高维数据(比如，我们的14214维表达矩阵)映射到二维空间。和PCA不同的是，tSNE算法具有随机性，即在同一数据集上运行结果可能不同。由于非线性和随机性，tSNE结果难以直观解释。为了确保可重复性，固定随机数"seed"，以便始终得到相同结果。

#### 质控前

```{r eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    umi[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 130
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-before-qc,fig.cap = "tSNE map of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-tsne-before-qc-1.png")
```
#### 质控后

```{r eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    umi.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 130
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-after-qc,fig.cap = "tSNE map of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-tsne-after-qc-1.png")
```

因为随机性和非线性，解释PCA和tSNE结果通常较难，不太直观，然而，在这种情况他们提供了相似的数据概览。比较图\@ref(fig:expr-overview-tsne-before-qc)和图\@ref(fig:expr-overview-tsne-after-qc)发现，质控过滤后的NA19098.r2样本不再是异常值。

tSNE中`perplexity`参数表示构建最近邻网络的邻居数，`perplexity`越高，网络越密集，细胞聚集在一起。`perplexity`越低，网络越稀疏，细胞群体彼此分离。`scater`使用默认perplexity为细胞总数除以5(向下取整)。

tSNE的缺点见[这里](http://distill.pub/2016/misread-tsne/)。

**练习2**
当perplexity设置为10或200时对tSNE结果的影响？

**答案**

```{r eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    umi.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 10
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-after-qc-exercise2-1, fig.cap = "tSNE map of the tung data (perplexity = 10)",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-tsne-after-qc-exercise2-1-1.png")
```

```{r eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    umi.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 200
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-after-qc-exercise2-2, fig.cap = "tSNE map of the tung data (perplexity = 200)",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-tsne-after-qc-exercise2-2-1.png")
```
### 大作业

使用Blischak数据的read counts数据完成相同的分析，使用`tung/reads.rds`文件导入reads的SCE对象。完成后的结果与我们相比较(下一章)。

## Reads数据可视化

```{r, message=FALSE, warning=FALSE,eval=FALSE}
library(scater)
options(stringsAsFactors = FALSE)
reads <- readRDS("data/tung/reads.rds")
reads.qc <- reads[rowData(reads)$use, colData(reads)$use]
endog_genes <- !rowData(reads.qc)$is_feature_control
```

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center')
```

```{r,eval=FALSE}
tmp <- runPCA(
  reads[endog_genes, ],
  exprs_values = "counts"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-before-qc-reads1, fig.cap = "PCA plot of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview-reads_files/figure-html/expr-overview-pca-before-qc-reads1-1.png")
```
```{r eval=FALSE}
tmp <- runPCA(
  reads[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-before-qc-reads2, fig.cap = "PCA plot of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview-reads_files/figure-html/expr-overview-pca-before-qc-reads2-1.png")
```
```{r eval=FALSE}
tmp <- runPCA(
  reads.qc[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-pca-after-qc-reads, fig.cap = "PCA plot of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview-reads_files/figure-html/expr-overview-pca-after-qc-reads-1.png")
```
```{r,eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    reads[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 130
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-before-qc-reads, fig.cap = "tSNE map of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview-reads_files/figure-html/expr-overview-tsne-before-qc-reads-1.png")
```
```{r eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    reads.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 130
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-after-qc-reads, fig.cap = "tSNE map of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview-reads_files/figure-html/expr-overview-tsne-after-qc-reads-1.png")
```
```{r eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    reads.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 10
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-after-qc-exercise3-1, fig.cap = "tSNE map of the tung data (perplexity = 10)",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview-reads_files/figure-html/expr-overview-tsne-after-qc-exercise2-1-1.png")
```
```{r eval=FALSE}
set.seed(123456)
tmp <- runTSNE(
    reads.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    perplexity = 200
)
plotTSNE(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r expr-overview-tsne-after-qc-exercise3-2, fig.cap = "tSNE map of the tung data (perplexity = 200)",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview-reads_files/figure-html/expr-overview-tsne-after-qc-exercise2-2-1.png")
```

## 识别混淆因子

### 介绍

scRNA-seq数据中存在大量潜在的混淆因子，假象和偏差。分析scRNA-seq数据的一个主要挑战是难以进行真正的技术重复来区分生物变异和技术变异。前面的章节中考虑了批次效应，本章节将继续探索如何识别和移除实验假象。`scater`包提供了一套专门用于实验和解释变量质控的方法。而且，我们将继续使用上一章节的Blichak数据。

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center')
```

```{r, message=FALSE, warning=FALSE}
library(scater, quietly = TRUE)
options(stringsAsFactors = FALSE)
umi <- readRDS("data/tung/umi.rds")
umi.qc <- umi[rowData(umi)$use, colData(umi)$use]
endog_genes <- !rowData(umi.qc)$is_feature_control
```

`umi.qc`数据集包含过滤后的细胞和基因。下一步将探索数据变异的技术驱动因素，以便在下游分析前进行数据标准化。

### 和组成分的相关性

首先查看质控后数据集的PCA图：
```{r eval=FALSE}
tmp <- runPCA(
  umi.qc[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts"
)
```
```{r confound-pca, fig.cap = "PCA plot of the tung data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/confounders_files/figure-html/confound-pca-1.png")
```

`scater` allows one to identify principal components that correlate with experimental and QC variables of interest (it ranks principle components by $R^2$ from a linear model regressing PC value against the variable of interest).

Let's test whether some of the variables correlate with any of the PCs.

#### Detected genes

```{r confound-find-pcs-total-features, fig.cap = "PC correlation with the number of detected genes", fig.asp=1}
logcounts(umi.qc) <- assay(umi.qc, "logcounts_raw")
plotExplanatoryPCs(
  umi.qc[endog_genes, ],
  variables = "total_features_by_counts"
)
logcounts(umi.qc) <- NULL
```

Indeed, we can see that `PC1` can be almost completely explained by the number of detected genes. In fact, it was also visible on the PCA plot above. This is a well-known issue in scRNA-seq and was described [here](http://biorxiv.org/content/early/2015/12/27/025528).

### Explanatory variables

`scater` can also compute the marginal $R^2$ for each variable when fitting a linear model regressing expression values for each gene against just that variable, and display a density plot of the gene-wise marginal $R^2$ values for the variables.

```{r confound-find-expl-vars, fig.cap = "Explanatory variables"}
plotExplanatoryVariables(
    umi.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    variables = c(
        "total_features_by_counts",
        "total_counts",
        "batch",
        "individual",
        "pct_counts_ERCC",
        "pct_counts_MT"
    )
)
```

This analysis indicates that the number of detected genes (again) and also the sequencing depth (number of counts) have substantial explanatory power for many genes, so these variables are good candidates for conditioning out in a normalisation step, or including in downstream statistical models. Expression of ERCCs also appears to be an important explanatory variable and one notable feature of the above plot is that batch explains more than individual. What does that tell us about the technical and biological variability of the data?

### Other confounders

In addition to correcting for batch, there are other factors that one
may want to compensate for. As with batch correction, these
adjustments require extrinsic information. One popular method is
[scLVM](https://github.com/PMBio/scLVM) which allows you to identify
and subtract the effect from processes such as cell-cycle or
apoptosis.

In addition, protocols may differ in terms of their coverage of each transcript, 
their bias based on the average content of __A/T__ nucleotides, or their ability to capture short transcripts.
Ideally, we would like to compensate for all of these differences and biases.

### Exercise

Perform the same analysis with read counts of the Blischak data. Use `tung/reads.rds` file to load the reads SCESet object. Once you have finished please compare your results to ours (next chapter).


## Identifying confounding factors (Reads)

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(scater, quietly = TRUE)
library(knitr)
options(stringsAsFactors = FALSE)
opts_chunk$set(out.width='90%', fig.align = 'center', echo=FALSE)
reads <- readRDS("data/tung/reads.rds")
reads.qc <- reads[rowData(reads)$use, colData(reads)$use]
endog_genes <- !rowData(reads.qc)$is_feature_control
```

```{r confound-pca-reads, fig.cap = "PCA plot of the tung data"}
tmp <- runPCA(
  reads.qc[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts"
)
```

```{r confound-find-pcs-total-features-reads, fig.cap = "PC correlation with the number of detected genes", fig.asp=1}
logcounts(reads.qc) <- assay(reads.qc, "logcounts_raw")
plotExplanatoryPCs(
  reads.qc[endog_genes, ],
  variables = "total_features_by_counts"
)
logcounts(reads.qc) <- NULL
```

```{r confound-find-expl-vars-reads, fig.cap = "Explanatory variables"}
plotExplanatoryVariables(
    reads.qc[endog_genes, ],
    exprs_values = "logcounts_raw",
    variables = c(
        "total_features_by_counts",
        "total_counts",
        "batch",
        "individual",
        "pct_counts_ERCC",
        "pct_counts_MT"
    )
)
```

## Normalization theory

### Introduction

```{r, echo=FALSE}
library(scRNA.seq.funcs)
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center')
insert_fun <- function(name) {
  read_chunk(lines = capture.output(dump(name, '')), labels = paste(name, 'source', sep = '-'))
}
insert_fun('calc_cpm')
insert_fun('calc_sf')
insert_fun('calc_uq')
insert_fun('calc_cell_RLE')
insert_fun('Down_Sample_Matrix')
```

In the previous chapter we identified important confounding factors and explanatory variables. `scater` allows one to account for these variables in subsequent statistical models or to condition them out using `normaliseExprs()`, if so desired. This can be done by providing a design matrix to `normaliseExprs()`. We are not covering this topic here, but you can try to do it yourself as an exercise.

Instead we will explore how simple size-factor normalisations correcting for library size can remove the effects of some of the confounders and explanatory variables.

### Library size

Library sizes vary because scRNA-seq data is often sequenced on highly multiplexed platforms the total reads which are derived from each cell may differ substantially. Some quantification methods
(eg. [`Cufflinks`](http://cole-trapnell-lab.github.io/cufflinks/), [`RSEM`](http://deweylab.github.io/RSEM/)) incorporated library size when determining gene expression estimates thus do not require this normalization.

However, if another quantification method was used then library size must be corrected for by multiplying or dividing each column of the expression matrix by a "normalization factor" which is an estimate of the library size relative to the other cells. Many methods to correct for library size have been developped for bulk RNA-seq and can be equally applied to scRNA-seq (eg. __UQ__, __SF__, __CPM__, __RPKM__, __FPKM__, __TPM__). 


### Normalisations

#### CPM

The simplest way to normalize this data is to convert it to counts per
million (__CPM__) by dividing each column by its total then multiplying by
1,000,000. Note that spike-ins should be excluded from the
calculation of total expression in order to correct for total cell RNA
content, therefore we will only use endogenous genes. Example of a __CPM__ function in `R`:

```{r calc_cpm-source, eval=FALSE,echo=TRUE}
calc_cpm <-
function (expr_mat, spikes = NULL) 
{
    norm_factor <- colSums(expr_mat[-spikes, ])
    return(t(t(expr_mat)/norm_factor)) * 10^6
}
```

One potential drawback of __CPM__ is if your sample contains genes that are both very highly expressed and differentially expressed across the cells. In this case, the total molecules in the cell may depend of whether such genes are on/off in the cell and normalizing by total molecules may hide the differential expression of those genes and/or falsely create differential expression for the remaining genes. 

__Note__ __RPKM__, __FPKM__ and __TPM__ are variants on __CPM__ which further adjust counts by the length of the respective gene/transcript.

To deal with this potentiality several other measures were devised.

#### RLE (SF)

The __size factor (SF)__ was proposed and popularized by DESeq [@Anders2010-jr]. First the geometric mean of each gene across all cells is calculated. The size factor for each cell is the median across genes of the ratio of the expression to the gene's geometric mean. A drawback to this method is that since it uses the geometric mean only genes with non-zero expression values across all cells can be used in its calculation, making it unadvisable for large low-depth scRNASeq experiments. `edgeR` & `scater` call this method __RLE__ for "relative log expression". Example of a __SF__ function in `R`:

```{r calc_sf-source, eval=FALSE,echo=TRUE}
calc_sf <-
function (expr_mat, spikes = NULL) 
{
    geomeans <- exp(rowMeans(log(expr_mat[-spikes, ])))
    SF <- function(cnts) {
        median((cnts/geomeans)[(is.finite(geomeans) & geomeans > 
            0)])
    }
    norm_factor <- apply(expr_mat[-spikes, ], 2, SF)
    return(t(t(expr_mat)/norm_factor))
}
```

#### UQ

The __upperquartile (UQ)__ was proposed by [@Bullard2010-eb]. Here each column is divided by the 75% quantile of the counts for each library. Often the calculated quantile is scaled by the median across cells to keep the absolute level of expression relatively consistent. A drawback to this method is that for low-depth scRNASeq experiments the large number of undetected genes may result in the 75% quantile being zero (or close to it). This limitation can be overcome by generalizing the idea and using a higher quantile (eg. the 99% quantile is the default in scater) or by excluding zeros prior to calculating the 75% quantile. Example of a __UQ__ function in `R`:

```{r calc_uq-source, eval=FALSE,echo=TRUE}
calc_uq <-
function (expr_mat, spikes = NULL) 
{
    UQ <- function(x) {
        quantile(x[x > 0], 0.75)
    }
    uq <- unlist(apply(expr_mat[-spikes, ], 2, UQ))
    norm_factor <- uq/median(uq)
    return(t(t(expr_mat)/norm_factor))
}
```

#### TMM

Another method is called __TMM__ is the weighted trimmed mean of M-values (to the reference) proposed by [@Robinson2010-hz]. The M-values in question are the gene-wise log2 fold changes between individual cells. One cell is used as the reference then the M-values for each other cell is calculated compared  to this reference. These values are then trimmed by removing the top and bottom ~30%, and the average of the remaining values is calculated by weighting them to account for the effect of the log scale on variance. Each non-reference cell is multiplied by the calculated factor. Two potential issues with this method are insufficient non-zero genes left after trimming, and the assumption that most genes are not differentially expressed.

#### scran

`scran` package implements a variant on __CPM__ specialized for single-cell data [@L_Lun2016-pq]. Briefly this method deals with the problem of vary large numbers of zero values per cell by pooling cells together calculating a normalization factor (similar to __CPM__) for the sum of each pool. Since each cell is found in many different pools, cell-specific factors can be deconvoluted from the collection of pool-specific factors using linear algebra. 

#### Downsampling

A final way to correct for library size is to downsample the expression matrix so that each cell has approximately the same total number of molecules. The benefit of this method is that zero values will be introduced by the down sampling thus eliminating any biases due to differing numbers of detected genes. However, the major drawback is that the process is not deterministic so each time the downsampling is run the resulting expression matrix is slightly different. Thus, often analyses must be run on multiple downsamplings to ensure results are robust. Example of a __downsampling__ function in `R`:

```{r Down_Sample_Matrix-source, eval=FALSE,echo=TRUE}
Down_Sample_Matrix <-
function (expr_mat) 
{
    min_lib_size <- min(colSums(expr_mat))
    down_sample <- function(x) {
        prob <- min_lib_size/sum(x)
        return(unlist(lapply(x, function(y) {
            rbinom(1, y, prob)
        })))
    }
    down_sampled_mat <- apply(expr_mat, 2, down_sample)
    return(down_sampled_mat)
}
```

### Effectiveness

to compare the efficiency of different normalization methods we will use visual inspection of `PCA` plots and calculation of cell-wise _relative log expression_ via `scater`'s `plotRLE()` function. Namely, cells with many (few) reads have higher (lower) than median expression for most genes resulting in a positive (negative) _RLE_ across the cell, whereas normalized cells have an _RLE_ close to zero. Example of a _RLE_ function in `R`:

```{r calc_cell_RLE-source, eval=FALSE,echo=TRUE}
calc_cell_RLE <-
function (expr_mat, spikes = NULL) 
{
    RLE_gene <- function(x) {
        if (median(unlist(x)) > 0) {
            log((x + 1)/(median(unlist(x)) + 1))/log(2)
        }
        else {
            rep(NA, times = length(x))
        }
    }
    if (!is.null(spikes)) {
        RLE_matrix <- t(apply(expr_mat[-spikes, ], 1, RLE_gene))
    }
    else {
        RLE_matrix <- t(apply(expr_mat, 1, RLE_gene))
    }
    cell_RLE <- apply(RLE_matrix, 2, median, na.rm = T)
    return(cell_RLE)
}
```

__Note__ The __RLE__, __TMM__, and __UQ__ size-factor methods were developed for bulk RNA-seq data and, depending on the experimental context, may not be appropriate for single-cell RNA-seq data, as their underlying assumptions may be problematically violated. 

__Note__ `scater` acts as a wrapper for the `calcNormFactors` function from `edgeR` which implements several library size normalization methods making it easy to apply any of these methods to our data.

__Note__ `edgeR` makes extra adjustments to some of the normalization methods which may result in somewhat different results than if the original methods are followed exactly, e.g. edgeR's and scater's "RLE" method which is based on the "size factor" used by [DESeq](http://bioconductor.org/packages/DESeq) may give different results to the `estimateSizeFactorsForMatrix` method in the `DESeq`/`DESeq2` packages. In addition, some versions of `edgeR` will not calculate the normalization factors correctly unless `lib.size` is set at 1 for all cells.

__Note__ For __CPM__ normalisation we use `scater`'s `calculateCPM()` function. For __RLE__, __UQ__ and __TMM__ we used to use `scater`'s `normaliseExprs()` function (it is deprecated now and therefore we removed the corresponding subchapters). For __scran__ we use `scran` package to calculate size factors (it also operates on `SingleCellExperiment` class) and `scater`'s `normalize()` to normalise the data. All these normalization functions save the results to the `logcounts` slot of the `SCE` object. For __downsampling__ we use our own functions shown above.

## Normalization practice (UMI)

We will continue to work with the `tung` data that was used in the previous chapter.

```{r, message=FALSE, warning=FALSE,echo=TRUE}
library(scRNA.seq.funcs)
library(scater)
library(scran)
options(stringsAsFactors = FALSE)
set.seed(1234567)
umi <- readRDS("data/tung/umi.rds")
umi.qc <- umi[rowData(umi)$use, colData(umi)$use]
endog_genes <- !rowData(umi.qc)$is_feature_control
```

### Raw
```{r norm-pca-raw, fig.cap = "PCA plot of the tung data",,echo=TRUE}
tmp <- runPCA(
  umi.qc[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```

### CPM
```{r norm-pca-cpm, fig.cap = "PCA plot of the tung data after CPM normalisation",echo=TRUE}
logcounts(umi.qc) <- log2(calculateCPM(umi.qc, use_size_factors = FALSE) + 1)
plotPCA(
    umi.qc[endog_genes, ],
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r norm-ours-rle-cpm, fig.cap = "Cell-wise RLE of the tung data"}
plotRLE(
    umi.qc[endog_genes, ], 
    exprs_values = "logcounts_raw",
    colour_by = "batch"
)
plotRLE(
    umi.qc[endog_genes, ], 
    exprs_values = "logcounts",
    colour_by = "batch"
)
```

### scran
```{r norm-pca-lsf, fig.cap = "PCA plot of the tung data after LSF normalisation",cache=TRUE,echo=TRUE}
qclust <- quickCluster(umi.qc, min.size = 30)
umi.qc <- computeSumFactors(umi.qc, sizes = 15, clusters = qclust)
umi.qc <- normalize(umi.qc)
plotPCA(
    umi.qc[endog_genes, ],
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r norm-ours-rle-scran, fig.cap = "Cell-wise RLE of the tung data",echo=TRUE}
plotRLE(
    umi.qc[endog_genes, ], 
    exprs_values = "logcounts_raw",
    colour_by = "batch"
)
plotRLE(
    umi.qc[endog_genes, ], 
    exprs_values = "logcounts",
    colour_by = "batch"
)
```
scran sometimes calculates negative or zero size factors. These will completely distort the normalized expression matrix. 
We can check the size factors scran has computed like so:
```{r,echo=TRUE}
summary(sizeFactors(umi.qc))
```
For this dataset all the size factors are reasonable so we are done. If you find scran has calculated negative size factors try increasing the cluster and pool sizes until they are all positive.

### Downsampling 

```{r norm-pca-downsample, fig.cap = "PCA plot of the tung data after downsampling",cache=TRUE,echo=TRUE}
logcounts(umi.qc) <- log2(Down_Sample_Matrix(counts(umi.qc)) + 1)
plotPCA(
    umi.qc[endog_genes, ],
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r norm-ours-rle-downsample, fig.cap = "Cell-wise RLE of the tung data",echo=TRUE}
plotRLE(
    umi.qc[endog_genes, ], 
    exprs_values = "logcounts_raw",
    colour_by = "batch"
)
plotRLE(
    umi.qc[endog_genes, ], 
    exprs_values = "logcounts",
    colour_by = "batch"
)
```

### Normalisation for gene/transcript length

Some methods combine library size and fragment/gene length normalization such as:

* __RPKM__ - Reads Per Kilobase Million (for single-end sequencing)
* __FPKM__ - Fragments Per Kilobase Million (same as __RPKM__ but for paired-end sequencing, makes sure that paired ends mapped to the same fragment are not counted twice)
* __TPM__ - Transcripts Per Kilobase Million (same as __RPKM__, but the order of normalizations is reversed - length first and sequencing depth second)

These methods are not applicable to our dataset since the end
of the transcript which contains the UMI was preferentially
sequenced. Furthermore in general these should only be calculated
using appropriate quantification software from aligned BAM files not
from read counts since often only a portion of the entire
gene/transcript is sequenced, not the entire length. If in doubt check 
for a relationship between gene/transcript length and expression level.

However, here we show how these normalisations can be calculated using `scater`. First, we need to find the effective transcript length in Kilobases. However, our dataset containes only gene IDs, therefore we will be using the gene lengths instead of transcripts. `scater` uses the [biomaRt](https://bioconductor.org/packages/release/bioc/html/biomaRt.html) package, which allows one to annotate genes by other attributes:
```{r, message = FALSE, warning = FALSE,eval=FALSE,echo=TRUE}
umi.qc <- getBMFeatureAnnos(
    umi.qc,
    filters = "ensembl_gene_id", 
    attributes = c(
        "ensembl_gene_id",
        "hgnc_symbol",
        "chromosome_name",
        "start_position",
        "end_position"
    ), 
    biomart = "ENSEMBL_MART_ENSEMBL", 
    dataset = "hsapiens_gene_ensembl",
    host = "www.ensembl.org"
)

# If you have mouse data, change the arguments based on this example:
# getBMFeatureAnnos(
#     object,
#     filters = "ensembl_transcript_id",
#     attributes = c(
#         "ensembl_transcript_id",
#         "ensembl_gene_id", 
#         "mgi_symbol",
#         "chromosome_name",
#         "transcript_biotype",
#         "transcript_start",
#         "transcript_end",
#         "transcript_count"
#     ),
#     biomart = "ENSEMBL_MART_ENSEMBL",
#     dataset = "mmusculus_gene_ensembl",
#     host = "www.ensembl.org"
# )
```

Some of the genes were not annotated, therefore we filter them out:
```{r,eval=FALSE,echo=TRUE}
umi.qc.ann <- umi.qc[!is.na(rowData(umi.qc)$ensembl_gene_id), ]
```

Now we compute the total gene length in Kilobases by using the `end_position` and `start_position` fields:
```{r,eval=FALSE,echo=TRUE}
eff_length <- 
    abs(rowData(umi.qc.ann)$end_position - rowData(umi.qc.ann)$start_position) / 1000
```

```{r length-vs-mean-1, fig.cap = "Gene length vs Mean Expression for the raw data",eval=FALSE,echo=TRUE}
plot(eff_length, rowMeans(counts(umi.qc.ann)))
```
```{r length-vs-mean-2, fig.cap = "Gene length vs Mean Expression for the raw data",echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-norm_files/figure-html/length-vs-mean-1.png")
```


There is no relationship between gene length and mean expression so __FPKM__s & __TPM__s are inappropriate for this dataset. 
But we will demonstrate them anyway.

__Note__ Here calculate the total gene length instead of the total exon length. Many genes will contain lots of introns so their `eff_length` will be very different from what we have calculated. Please consider our calculation as approximation. If you want to use the total exon lengths, please refer to [this page](https://www.biostars.org/p/83901/).

Now we are ready to perform the normalisations:
```{r,eval=FALSE,echo=TRUE}
tpm(umi.qc.ann) <- log2(calculateTPM(umi.qc.ann, eff_length) + 1)
```

Plot the results as a PCA plot:
```{r norm-pca-fpkm-1, fig.cap = "PCA plot of the tung data after TPM normalisation",eval=FALSE,echo=TRUE}
tmp <- runPCA(
  umi.qc.ann,
  exprs_values = "tpm",
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```

```{r norm-pca-fpkm-2, fig.cap = "PCA plot of the tung data after TPM normalisation"}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-norm_files/figure-html/norm-pca-fpkm-1.png")
```

```{r,eval=FALSE,echo=TRUE}
tpm(umi.qc.ann) <- log2(calculateFPKM(umi.qc.ann, eff_length) + 1)
```

```{r norm-pca-tpm-1, fig.cap = "PCA plot of the tung data after FPKM normalisation",eval=FALSE,echo=TRUE}
tmp <- runPCA(
  umi.qc.ann,
  exprs_values = "tpm",
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```

```{r norm-pca-tpm-2, fig.cap = "PCA plot of the tung data after FPKM normalisation",eval=FALSE,echo=TRUE}

knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-norm_files/figure-html/norm-pca-tpm-1.png")
```
__Note__ The `PCA` looks for differences between cells. Gene length is the same across cells for each gene thus __FPKM__ is almost identical to the __CPM__ plot (it is just rotated) since it performs __CPM__ first then normalizes gene length. Whereas, __TPM__ is different because it weights genes by their length before performing __CPM__. 

### Exercise

Perform the same analysis with read counts of the `tung` data. Use `tung/reads.rds` file to load the reads `SCE` object. Once you have finished please compare your results to ours (next chapter).

## Normalization practice (Reads)

```{r, echo=FALSE, message=FALSE, warning=FALSE,echo=TRUE}
library(scRNA.seq.funcs)
library(scater)
library(scran)
options(stringsAsFactors = FALSE)
set.seed(1234567)
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center', echo=FALSE)
reads <- readRDS("data/tung/reads.rds")
reads.qc <- reads[rowData(reads)$use, colData(reads)$use]
endog_genes <- !rowData(reads.qc)$is_feature_control
```

```{r norm-pca-raw-reads, fig.cap = "PCA plot of the tung data",echo=TRUE}
tmp <- runPCA(
  reads.qc[endog_genes, ],
  exprs_values = "logcounts_raw"
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```

```{r norm-pca-cpm-reads, fig.cap = "PCA plot of the tung data after CPM normalisation",echo=TRUE}
logcounts(reads.qc) <- log2(calculateCPM(reads.qc, use_size_factors = FALSE) + 1)
plotPCA(
    reads.qc[endog_genes, ],
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r norm-ours-rle-cpm-reads, fig.cap = "Cell-wise RLE of the tung data", warning=FALSE,echo=TRUE}
plotRLE(
    reads.qc[endog_genes, ], 
    exprs_values = "logcounts_raw",
    colour_by = "batch"
)
plotRLE(
    reads.qc[endog_genes, ], 
    exprs_values = "logcounts",
    colour_by = "batch"
)
```

```{r norm-pca-lsf-umi, fig.cap = "PCA plot of the tung data after LSF normalisation",echo=TRUE}
qclust <- quickCluster(reads.qc, min.size = 30)
reads.qc <- computeSumFactors(reads.qc, sizes = 15, clusters = qclust)
reads.qc <- normalize(reads.qc)
plotPCA(
    reads.qc[endog_genes, ],
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```

```{r norm-ours-rle-scran-reads, fig.cap = "Cell-wise RLE of the tung data",echo=TRUE}
plotRLE(
    reads.qc[endog_genes, ], 
    exprs_values = "logcounts_raw",
    colour_by = "batch"
)
plotRLE(
    reads.qc[endog_genes, ], 
    exprs_values = "logcounts",
    colour_by = "batch"
)
```

```{r norm-pca-downsample-reads, fig.cap = "PCA plot of the tung data after downsampling",echo=TRUE}
logcounts(reads.qc) <- log2(Down_Sample_Matrix(counts(reads.qc)) + 1)
plotPCA(
    reads.qc[endog_genes, ],
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r norm-ours-rle-downsample-reads, fig.cap = "Cell-wise RLE of the tung data",echo=TRUE}
plotRLE(
    reads.qc[endog_genes, ], 
    exprs_values = "logcounts_raw",
    colour_by = "batch"
)
plotRLE(
    reads.qc[endog_genes, ], 
    exprs_values = "logcounts",
    colour_by = "batch"
)
```

```{r,eval=FALSE,echo=TRUE}
reads.qc <- getBMFeatureAnnos(
    reads.qc,
    filters = "ensembl_gene_id", 
    attributes = c(
        "ensembl_gene_id",
        "hgnc_symbol",
        "chromosome_name",
        "start_position",
        "end_position"
    ), 
    biomart = "ENSEMBL_MART_ENSEMBL", 
    dataset = "hsapiens_gene_ensembl",
    host = "www.ensembl.org"
)
```

```{r,eval=FALSE,echo=TRUE}
reads.qc.ann <- reads.qc[!is.na(rowData(reads.qc)$ensembl_gene_id), ]
```

```{r,eval=FALSE,echo=TRUE}
eff_length <- 
    abs(rowData(reads.qc.ann)$end_position - rowData(reads.qc.ann)$start_position) / 1000
```

```{r,eval=FALSE,echo=TRUE}
tpm(reads.qc.ann) <- log2(calculateTPM(reads.qc.ann, eff_length) + 1)
```

```{r norm-pca-tpm-reads-1, fig.cap = "PCA plot of the tung data after TPM normalisation",eval=FALSE,echo=TRUE}
tmp <- runPCA(
  reads.qc.ann,
  exprs_values = "tpm",
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```

```{r norm-pca-tpm-reads-2, fig.cap = "PCA plot of the tung data after TPM normalisation"}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-norm-reads_files/figure-html/norm-pca-tpm-reads-1.png")
```

```{r,eval=FALSE,echo=TRUE}
tpm(reads.qc.ann) <- log2(calculateFPKM(reads.qc.ann, eff_length) + 1)
```

```{r norm-pca-fpkm-reads, fig.cap = "PCA plot of the tung data after FPKM normalisation", eval=FALSE,echo=TRUE}
tmp <- runPCA(
  reads.qc.ann,
  exprs_values = "tpm",
)
plotPCA(
    tmp,
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```


## Dealing with confounders

### Introduction

In the previous chapter we normalized for library size, effectively removing it as a confounder. Now we will consider removing other less well defined confounders from our data. Technical confounders (aka batch effects) can arise from difference in reagents, isolation methods, the lab/experimenter who performed the experiment, even which day/time the experiment was performed. Accounting for technical confounders, and batch effects particularly, is a large topic that also involves principles of experimental design. Here we address approaches that can be taken to account for confounders when the experimental design is appropriate.

Fundamentally, accounting for technical confounders involves identifying and, ideally, removing sources of variation in the expression data that are not related to (i.e. are confounding) the biological signal of interest. Various approaches exist, some of which use spike-in or housekeeping genes, and some of which use endogenous genes.

#### Advantages and disadvantages of using spike-ins to remove confounders

The use of spike-ins as control genes is appealing, since the same amount of ERCC (or other) spike-in was added to each cell in our experiment. In principle, all the variablity we observe for these genes is due to technical noise; whereas endogenous genes are affected by both technical noise and biological variability. Technical noise can be removed by fitting a model to the spike-ins and "substracting" this from the endogenous genes. There are several methods available based on this premise (eg. [BASiCS](https://github.com/catavallejos/BASiCS), [scLVM](https://github.com/PMBio/scLVM), [RUVg](http://bioconductor.org/packages/release/bioc/html/RUVSeq.html)); each using different noise models and different fitting procedures. Alternatively, one can identify genes which exhibit significant variation beyond technical noise (eg. Distance to median, [Highly variable genes](http://www.nature.com/nmeth/journal/v10/n11/full/nmeth.2645.html)). However, there are issues with the use of spike-ins for normalisation (particularly ERCCs, derived from bacterial sequences), including that their variability can, for various reasons, actually be *higher* than that of endogenous genes.

Given the issues with using spike-ins, better results can often be obtained by using endogenous genes instead. Where we have a large number of endogenous genes that, on average, do not vary systematically between cells and where we expect technical effects to affect a large number of genes (a very common and reasonable assumption), then such methods (for example, the RUVs method) can perform well. 

We explore both general approaches below.

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(fig.align = 'center')
```

```{r, message=FALSE, warning=FALSE,eval=FALSE,echo=TRUE}
library(scRNA.seq.funcs)
library(RUVSeq)
library(scater)
library(SingleCellExperiment)
library(scran)
library(kBET)
library(sva) # Combat
library(edgeR)
library(harmony)
set.seed(1234567)
options(stringsAsFactors = FALSE)
umi <- readRDS("data/tung/umi.rds")
umi.qc <- umi[rowData(umi)$use, colData(umi)$use]
endog_genes <- !rowData(umi.qc)$is_feature_control
erccs <- rowData(umi.qc)$is_feature_control

qclust <- quickCluster(umi.qc, min.size = 30)
umi.qc <- computeSumFactors(umi.qc, sizes = 15, clusters = qclust)
umi.qc <- normalize(umi.qc)
```

### Remove Unwanted Variation

Factors contributing to technical noise frequently appear as "batch
effects" where cells processed on different days or by different
technicians systematically vary from one another. Removing technical
noise and correcting for batch effects can frequently be performed
using the same tool or slight variants on it. We will be considering
the [Remove Unwanted Variation (RUVSeq)](http://bioconductor.org/packages/RUVSeq). Briefly, RUVSeq works as follows. For $n$ samples and $J$ genes, consider the following generalized linear model (GLM), where the RNA-Seq read counts are regressed on both the known covariates of interest and unknown factors of unwanted variation:
\[\log E[Y|W,X,O] = W\alpha + X\beta + O\]
Here, $Y$ is the $n \times J$ matrix of observed gene-level read counts, $W$ is an $n \times k$ matrix corresponding to the factors of “unwanted variation” and $O$ is an $n \times J$ matrix of offsets that can either be set to zero or estimated with some other normalization procedure (such as upper-quartile normalization). The simultaneous estimation of $W$, $\alpha$, $\beta$, and $k$ is infeasible. For a given $k$, instead the following three
approaches to estimate the factors of unwanted variation $W$ are used:

* _RUVg_ uses negative control genes (e.g. ERCCs), assumed to have constant expression across samples;
* _RUVs_ uses centered (technical) replicate/negative control samples for which the covariates of interest are
constant;
* _RUVr_ uses residuals, e.g., from a first-pass GLM regression of the counts on the covariates of interest.

We will concentrate on the first two approaches.

#### RUVg

```{r, message=FALSE, warning=FALSE,eval=FALSE,echo=TRUE}
ruvg <- RUVg(counts(umi.qc), erccs, k = 1)
assay(umi.qc, "ruvg1") <- log2(
    t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1
)
ruvg <- RUVg(counts(umi.qc), erccs, k = 10)
assay(umi.qc, "ruvg10") <- log2(
    t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1
)
```

#### RUVs

```{r,eval=FALSE,echo=TRUE}
scIdx <- matrix(-1, ncol = max(table(umi.qc$individual)), nrow = 3)
tmp <- which(umi.qc$individual == "NA19098")
scIdx[1, 1:length(tmp)] <- tmp
tmp <- which(umi.qc$individual == "NA19101")
scIdx[2, 1:length(tmp)] <- tmp
tmp <- which(umi.qc$individual == "NA19239")
scIdx[3, 1:length(tmp)] <- tmp
cIdx <- rownames(umi.qc)
ruvs <- RUVs(counts(umi.qc), cIdx, k = 1, scIdx = scIdx, isLog = FALSE)
assay(umi.qc, "ruvs1") <- log2(
    t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1
)
ruvs <- RUVs(counts(umi.qc), cIdx, k = 10, scIdx = scIdx, isLog = FALSE)
assay(umi.qc, "ruvs10") <- log2(
    t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1
)
```

### Combat

If you have an experiment with a balanced design, `Combat` can be used to eliminate batch effects while preserving biological effects by specifying the biological effects using the `mod` parameter. However the `Tung` data contains multiple experimental replicates rather than a balanced design so using `mod1` to preserve biological variability will result in an error. 
```{r message=FALSE, warning=FALSE, paged.print=FALSE,eval=FALSE,echo=TRUE}
combat_data <- logcounts(umi.qc)
mod_data <- as.data.frame(t(combat_data))
# Basic batch removal
mod0 = model.matrix(~ 1, data = mod_data) 
# Preserve biological variability
mod1 = model.matrix(~ umi.qc$individual, data = mod_data) 
# adjust for total genes detected
mod2 = model.matrix(~ umi.qc$total_features_by_counts, data = mod_data)
assay(umi.qc, "combat") <- ComBat(
    dat = t(mod_data), 
    batch = factor(umi.qc$batch), 
    mod = mod0,
    par.prior = TRUE,
    prior.plots = FALSE
)
```

__Exercise 1__

Perform `ComBat` correction accounting for total features as a co-variate. Store the corrected matrix in the `combat_tf` slot.

```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE,eval=FALSE,echo=TRUE}
assay(umi.qc, "combat_tf") <- ComBat(
    dat = t(mod_data), 
    batch = factor(umi.qc$batch), 
    mod = mod2,
    par.prior = TRUE,
    prior.plots = FALSE
)
```

### mnnCorrect 
`mnnCorrect` [@Haghverdi2017-vh] assumes that each batch shares at least one biological condition with each other batch. Thus it works well for a variety of balanced experimental designs. However, the `Tung` data contains multiple replicates for each invidividual rather than balanced batches, thus we will normalized each individual separately. Note that this will remove batch effects between batches within the same individual but not the batch effects between batches in different individuals, due to the confounded experimental design. 

Thus we will merge a replicate from each individual to form three batches. 
```{r,eval=FALSE,echo=TRUE}
do_mnn <- function(data.qc) {
    batch1 <- logcounts(data.qc[, data.qc$replicate == "r1"])
    batch2 <- logcounts(data.qc[, data.qc$replicate == "r2"])
    batch3 <- logcounts(data.qc[, data.qc$replicate == "r3"])
    
    if (ncol(batch2) > 0) {
        x = mnnCorrect(
          batch1, batch2, batch3,  
          k = 20,
          sigma = 0.1,
          cos.norm.in = TRUE,
          svd.dim = 2
        )
        res1 <- x$corrected[[1]]
        res2 <- x$corrected[[2]]
        res3 <- x$corrected[[3]]
        dimnames(res1) <- dimnames(batch1)
        dimnames(res2) <- dimnames(batch2)
        dimnames(res3) <- dimnames(batch3)
        return(cbind(res1, res2, res3))
    } else {
        x = mnnCorrect(
          batch1, batch3,  
          k = 20,
          sigma = 0.1,
          cos.norm.in = TRUE,
          svd.dim = 2
        )
        res1 <- x$corrected[[1]]
        res3 <- x$corrected[[2]]
        dimnames(res1) <- dimnames(batch1)
        dimnames(res3) <- dimnames(batch3)
        return(cbind(res1, res3))
    }
}

indi1 <- do_mnn(umi.qc[, umi.qc$individual == "NA19098"])
indi2 <- do_mnn(umi.qc[, umi.qc$individual == "NA19101"])
indi3 <- do_mnn(umi.qc[, umi.qc$individual == "NA19239"])

assay(umi.qc, "mnn") <- cbind(indi1, indi2, indi3)

# For a balanced design: 
#assay(umi.qc, "mnn") <- mnnCorrect(
#    list(B1 = logcounts(batch1), B2 = logcounts(batch2), B3 = logcounts(batch3)),  
#    k = 20,
#    sigma = 0.1,
#    cos.norm = TRUE,
#    svd.dim = 2
#)
```

### GLM
A general linear model is a simpler version of `Combat`. It can correct for batches while preserving biological effects if you have a balanced design. In a confounded/replicate design biological effects will not be fit/preserved. Similar to `mnnCorrect` we could remove batch effects from each individual separately in order to preserve biological (and technical) variance between individuals. For demonstation purposes we will naively correct all cofounded batch effects: 

```{r,eval=FALSE,echo=TRUE}
glm_fun <- function(g, batch, indi) {
  model <- glm(g ~ batch + indi)
  model$coef[1] <- 0 # replace intercept with 0 to preserve reference batch.
  return(model$coef)
}
effects <- apply(
    logcounts(umi.qc), 
    1, 
    glm_fun, 
    batch = umi.qc$batch, 
    indi = umi.qc$individual
)
corrected <- logcounts(umi.qc) - t(effects[as.numeric(factor(umi.qc$batch)), ])
assay(umi.qc, "glm") <- corrected
```

__Exercise 2__

Perform GLM correction for each individual separately. Store the final corrected matrix in the `glm_indi` slot.

```{r, echo=TRUE,eval=FALSE}
glm_fun1 <- function(g, batch) {
  model <- glm(g ~ batch)
  model$coef[1] <- 0 # replace intercept with 0 to preserve reference batch.
  return(model$coef)
}

do_glm <- function(data.qc) {
    effects <- apply(
        logcounts(data.qc), 
        1, 
        glm_fun1, 
        batch = data.qc$batch
    )
    corrected <- logcounts(data.qc) - t(effects[as.numeric(factor(data.qc$batch)), ])
    return(corrected)
}
indi1 <- do_glm(umi.qc[, umi.qc$individual == "NA19098"])
indi2 <- do_glm(umi.qc[, umi.qc$individual == "NA19101"])
indi3 <- do_glm(umi.qc[, umi.qc$individual == "NA19239"])

assay(umi.qc, "glm_indi") <- cbind(indi1, indi2, indi3);
```

### Harmony

Harmony [Korsunsky2018fast] is a newer batch correction method, which is designed to operate on PC space. The algorithm proceeds to iteratively cluster the cells, with the objective function formulated to promote cells from multiple datasets within each cluster. Once a clustering is obtained, the positions of the centroids of each dataset are obtained on a per-cluster basis and the coordinates are corrected. This procedure is iterated until convergence. Harmony comes with a `theta` parameter that controls the degree of batch correction (higher values lead to more dataset integration), and can account for multiple experimental and biological factors on input.

Seeing how the end result of Harmony is an altered dimensional reduction space created on the basis of PCA, we plot the obtained manifold here and exclude it from the rest of the follow-ups in the section.

```{r,eval=FALSE,echo=TRUE}
umi.qc.endog = umi.qc[endog_genes,]
umi.qc.endog = runPCA(umi.qc.endog, exprs_values = 'logcounts', ncomponents = 20)
pca <- as.matrix(umi.qc.endog@reducedDims@listData[["PCA"]])
harmony_emb <- HarmonyMatrix(pca, umi.qc.endog$batch, theta=2, do_pca=FALSE)
umi.qc.endog@reducedDims@listData[['harmony']] <- harmony_emb

plotReducedDim(
    umi.qc.endog,
    use_dimred = 'harmony',
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-10-1.png")
```

### How to evaluate and compare confounder removal strategies

A key question when considering the different methods for removing confounders is how to quantitatively determine which one is the most effective. The main reason why comparisons are challenging is because it is often difficult to know what corresponds to technical counfounders and what is interesting biological variability. Here, we consider three different metrics which are all reasonable based on our knowledge of the experimental design. Depending on the biological question that you wish to address, it is important to choose a metric that allows you to evaluate the confounders that are likely to be the biggest concern for the given situation.

#### Effectiveness 1

We evaluate the effectiveness of the normalization by inspecting the
PCA plot where colour corresponds the technical replicates and shape
corresponds to different biological samples (individuals). Separation of biological samples and
interspersed batches indicates that technical variation has been
removed. We always use log2-cpm normalized data to match the assumptions of PCA.

```{r,eval=FALSE,echo=TRUE}
for(n in assayNames(umi.qc)) {
    tmp <- runPCA(
        umi.qc[endog_genes, ],
        exprs_values = n
    )
    print(
        plotPCA(
            tmp,
            colour_by = "batch",
            size_by = "total_features_by_counts",
            shape_by = "individual"
        ) +
        ggtitle(n)
    )
}
```
```{r,echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-1.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-2.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-3.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-4.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-5.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-6.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-7.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-8.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-9.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-10.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-11.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-11-12.png")
```

__Exercise 3__

Consider different `ks` for RUV normalizations. Which gives the best results?

#### Effectiveness 2

We can also examine the effectiveness of correction using the relative log expression (RLE) across cells to confirm technical noise has been removed from the dataset. Note RLE only evaluates whether the number of genes higher and lower than average are equal for each cell - i.e. systemic technical effects. Random technical noise between batches may not be detected by RLE.

```{r,eval=FALSE,echo=TRUE}
res <- list()
for(n in assayNames(umi.qc)) {
	res[[n]] <- suppressWarnings(calc_cell_RLE(assay(umi.qc, n), erccs))
}
par(mar=c(6,4,1,1))
boxplot(res, las=2)
```
```{r}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-12-1.png")
```
#### Effectiveness 3

Another method to check the efficacy of batch-effect correction is to consider the intermingling of points from different batches in local subsamples of the data. If there are no batch-effects then proportion of cells from each batch in any local region should be equal to the global proportion of cells in each batch. 

`kBET` [@Buttner2017-ds] takes `kNN` networks around random cells and tests the number of cells from each batch against a binomial distribution. The rejection rate of these tests indicates the severity of batch-effects still present in the data (high rejection rate = strong batch effects). `kBET` assumes each batch contains the same complement of biological groups, thus it can only be applied to the entire dataset if a perfectly balanced design has been used. However, `kBET` can also be applied to replicate-data if it is applied to each biological group separately. In the case of the Tung data, we will apply `kBET` to each individual independently to check for residual batch effects. However, this method will not identify residual batch-effects which are confounded with biological conditions. In addition, `kBET` does not determine if biological signal has been preserved. 

```{r, message = FALSE,eval=FALSE,echo=TRUE}
compare_kBET_results <- function(sce){
    indiv <- unique(sce$individual)
    norms <- assayNames(sce) # Get all normalizations
    results <- list()
    for (i in indiv){ 
        for (j in norms){
            tmp <- kBET(
                df = t(assay(sce[,sce$individual== i], j)), 
                batch = sce$batch[sce$individual==i], 
                heuristic = TRUE, 
                verbose = FALSE, 
                addTest = FALSE, 
                plot = FALSE)
            results[[i]][[j]] <- tmp$summary$kBET.observed[1]
        }
    }
    return(as.data.frame(results))
}

eff_debatching <- compare_kBET_results(umi.qc)
```

```{r, message = FALSE,eval=FALSE,echo=TRUE}
require("reshape2")
require("RColorBrewer")
# Plot results
dod <- melt(as.matrix(eff_debatching),  value.name = "kBET")
colnames(dod)[1:2] <- c("Normalisation", "Individual")

colorset <- c('gray', brewer.pal(n = 9, "RdYlBu"))

ggplot(dod, aes(Normalisation, Individual, fill=kBET)) +  
    geom_tile() +
    scale_fill_gradient2(
        na.value = "gray",
        low = colorset[2],
        mid=colorset[6],
        high = colorset[10],
        midpoint = 0.5, limit = c(0,1)) +
    scale_x_discrete(expand = c(0, 0)) +
    scale_y_discrete(expand = c(0, 0)) + 
    theme(
        axis.text.x = element_text(
            angle = 45, 
            vjust = 1, 
            size = 12, 
            hjust = 1
        )
    ) + 
    ggtitle("Effect of batch regression methods per individual")
```
```{r}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf_files/figure-html/unnamed-chunk-14-1.png")
```
__Exercise 4__

Why do the raw counts appear to have little batch effects?

### Big Exercise

Perform the same analysis with read counts of the `tung` data. Use `tung/reads.rds` file to load the reads `SCE` object. Once you have finished please compare your results to ours (next chapter). Additionally, experiment with other combinations of normalizations and compare the results.


## Dealing with confounders (Reads)

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(fig.align = 'center')
```

```{r, message=FALSE, warning=FALSE,eval=FALSE,echo=TRUE}
library(scRNA.seq.funcs)
library(RUVSeq)
library(scater)
library(SingleCellExperiment)
library(scran)
library(kBET)
library(sva) # Combat
library(harmony)
library(edgeR)
set.seed(1234567)
options(stringsAsFactors = FALSE)
reads <- readRDS("data/tung/reads.rds")
reads.qc <- reads[rowData(reads)$use, colData(reads)$use]
endog_genes <- !rowData(reads.qc)$is_feature_control
erccs <- rowData(reads.qc)$is_feature_control

qclust <- quickCluster(reads.qc, min.size = 30)
reads.qc <- computeSumFactors(reads.qc, sizes = 15, clusters = qclust)
reads.qc <- normalize(reads.qc)
```

```{r, message=FALSE, warning=FALSE,eval=FALSE,echo=TRUE}
ruvg <- RUVg(counts(reads.qc), erccs, k = 1)
assay(reads.qc, "ruvg1") <- log2(
    t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1
)
ruvg <- RUVg(counts(reads.qc), erccs, k = 10)
assay(reads.qc, "ruvg10") <- log2(
    t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1
)
```

```{r,eval=FALSE,echo=TRUE}
scIdx <- matrix(-1, ncol = max(table(reads.qc$individual)), nrow = 3)
tmp <- which(reads.qc$individual == "NA19098")
scIdx[1, 1:length(tmp)] <- tmp
tmp <- which(reads.qc$individual == "NA19101")
scIdx[2, 1:length(tmp)] <- tmp
tmp <- which(reads.qc$individual == "NA19239")
scIdx[3, 1:length(tmp)] <- tmp
cIdx <- rownames(reads.qc)
ruvs <- RUVs(counts(reads.qc), cIdx, k = 1, scIdx = scIdx, isLog = FALSE)
assay(reads.qc, "ruvs1") <- log2(
    t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1
)
ruvs <- RUVs(counts(reads.qc), cIdx, k = 10, scIdx = scIdx, isLog = FALSE)
assay(reads.qc, "ruvs10") <- log2(
    t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1
)
```

```{r, eval = TRUE, message=FALSE, warning=FALSE,eval=FALSE,echo=TRUE}
combat_data <- logcounts(reads.qc)
mod_data <- as.data.frame(t(combat_data))
# Basic batch removal
mod0 = model.matrix(~ 1, data = mod_data) 
# Preserve biological variability
mod1 = model.matrix(~ reads.qc$individual, data = mod_data) 
# adjust for total genes detected
mod2 = model.matrix(~ reads.qc$total_features_by_counts, data = mod_data)
assay(reads.qc, "combat") <- ComBat(
    dat = t(mod_data), 
    batch = factor(reads.qc$batch), 
    mod = mod0,
    par.prior = TRUE,
    prior.plots = FALSE
)
```

__Exercise 1__

```{r, eval = TRUE, echo = FALSE, message=FALSE, warning=FALSE,eval=FALSE,echo=TRUE}
assay(reads.qc, "combat_tf") <- ComBat(
    dat = t(mod_data), 
    batch = factor(reads.qc$batch), 
    mod = mod2,
    par.prior = TRUE,
    prior.plots = FALSE
)
```

```{r,eval=FALSE,echo=TRUE}
do_mnn <- function(data.qc) {
    batch1 <- logcounts(data.qc[, data.qc$replicate == "r1"])
    batch2 <- logcounts(data.qc[, data.qc$replicate == "r2"])
    batch3 <- logcounts(data.qc[, data.qc$replicate == "r3"])
    
    if (ncol(batch2) > 0) {
        x = mnnCorrect(
          batch1, batch2, batch3,  
          k = 20,
          sigma = 0.1,
          cos.norm.in = TRUE,
          svd.dim = 2
        )
        res1 <- x$corrected[[1]]
        res2 <- x$corrected[[2]]
        res3 <- x$corrected[[3]]
        dimnames(res1) <- dimnames(batch1)
        dimnames(res2) <- dimnames(batch2)
        dimnames(res3) <- dimnames(batch3)
        return(cbind(res1, res2, res3))
    } else {
        x = mnnCorrect(
          batch1, batch3,  
          k = 20,
          sigma = 0.1,
          cos.norm.in = TRUE,
          svd.dim = 2
        )
        res1 <- x$corrected[[1]]
        res3 <- x$corrected[[2]]
        dimnames(res1) <- dimnames(batch1)
        dimnames(res3) <- dimnames(batch3)
        return(cbind(res1, res3))
    }
}

indi1 <- do_mnn(reads.qc[, reads.qc$individual == "NA19098"])
indi2 <- do_mnn(reads.qc[, reads.qc$individual == "NA19101"])
indi3 <- do_mnn(reads.qc[, reads.qc$individual == "NA19239"])

assay(reads.qc, "mnn") <- cbind(indi1, indi2, indi3)

# For a balanced design: 
#assay(reads.qc, "mnn") <- mnnCorrect(
#    list(B1 = logcounts(batch1), B2 = logcounts(batch2), B3 = logcounts(batch3)),  
#    k = 20,
#    sigma = 0.1,
#    cos.norm = TRUE,
#    svd.dim = 2
#)
```

```{r,eval=FALSE,echo=TRUE}
glm_fun <- function(g, batch, indi) {
  model <- glm(g ~ batch + indi)
  model$coef[1] <- 0 # replace intercept with 0 to preserve reference batch.
  return(model$coef)
}
effects <- apply(
    logcounts(reads.qc), 
    1, 
    glm_fun, 
    batch = reads.qc$batch, 
    indi = reads.qc$individual
)
corrected <- logcounts(reads.qc) - t(effects[as.numeric(factor(reads.qc$batch)), ])
assay(reads.qc, "glm") <- corrected
```

__Exercise 2__

```{r, echo=FALSE,eval=FALSE,echo=TRUE}
glm_fun1 <- function(g, batch) {
  model <- glm(g ~ batch)
  model$coef[1] <- 0 # replace intercept with 0 to preserve reference batch.
  return(model$coef)
}

do_glm <- function(data.qc) {
    effects <- apply(
        logcounts(data.qc), 
        1, 
        glm_fun1, 
        batch = data.qc$batch
    )
    corrected <- logcounts(data.qc) - t(effects[as.numeric(factor(data.qc$batch)), ])
    return(corrected)
}
indi1 <- do_glm(reads.qc[, reads.qc$individual == "NA19098"])
indi2 <- do_glm(reads.qc[, reads.qc$individual == "NA19101"])
indi3 <- do_glm(reads.qc[, reads.qc$individual == "NA19239"])

assay(reads.qc, "glm_indi") <- cbind(indi1, indi2, indi3);
```

```{r,eval=FALSE,echo=TRUE}
reads.qc.endog = reads.qc[endog_genes,]
reads.qc.endog = runPCA(reads.qc.endog, exprs_values = 'logcounts', ncomponents = 20)
pca <- as.matrix(reads.qc.endog@reducedDims@listData[["PCA"]])
harmony_emb <- HarmonyMatrix(pca, reads.qc.endog$batch, theta=2, do_pca=FALSE)
reads.qc.endog@reducedDims@listData[['harmony']] <- harmony_emb

plotReducedDim(
    reads.qc.endog,
    use_dimred = 'harmony',
    colour_by = "batch",
    size_by = "total_features_by_counts",
    shape_by = "individual"
)
```
```{r}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-10-1.png")
```
```{r,eval=FALSE,echo=TRUE}
for(n in assayNames(reads.qc)) {
    tmp <- runPCA(
        reads.qc[endog_genes, ],
        exprs_values = n
    )
    print(
        plotPCA(
            tmp,
            colour_by = "batch",
            size_by = "total_features_by_counts",
            shape_by = "individual"
        ) +
        ggtitle(n)
    )
}
```
```{r,echo=FALSE}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-1.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-2.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-3.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-4.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-5.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-6.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-7.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-8.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-9.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-10.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-11.png")
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-11-12.png")
```
```{r,eval=FALSE}
res <- list()
for(n in assayNames(reads.qc)) {
	res[[n]] <- suppressWarnings(calc_cell_RLE(assay(reads.qc, n), erccs))
}
par(mar=c(6,4,1,1))
boxplot(res, las=2)
```
```{r}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-12-1.png")
```
```{r, message = FALSE,eval=FALSE}
compare_kBET_results <- function(sce){
    indiv <- unique(sce$individual)
    norms <- assayNames(sce) # Get all normalizations
    results <- list()
    for (i in indiv){ 
        for (j in norms){
            tmp <- kBET(
                df = t(assay(sce[,sce$individual== i], j)), 
                batch = sce$batch[sce$individual==i], 
                heuristic = TRUE, 
                verbose = FALSE, 
                addTest = FALSE, 
                plot = FALSE)
            results[[i]][[j]] <- tmp$summary$kBET.observed[1]
        }
    }
    return(as.data.frame(results))
}

eff_debatching <- compare_kBET_results(reads.qc)
```

```{r, message = FALSE,eval=FALSE}
require("reshape2")
require("RColorBrewer")
# Plot results
dod <- melt(as.matrix(eff_debatching),  value.name = "kBET")
colnames(dod)[1:2] <- c("Normalisation", "Individual")

colorset <- c('gray', brewer.pal(n = 9, "RdYlBu"))

ggplot(dod, aes(Normalisation, Individual, fill=kBET)) +  
    geom_tile() +
    scale_fill_gradient2(
        na.value = "gray",
        low = colorset[2],
        mid=colorset[6],
        high = colorset[10],
        midpoint = 0.5, limit = c(0,1)) +
    scale_x_discrete(expand = c(0, 0)) +
    scale_y_discrete(expand = c(0, 0)) + 
    theme(
        axis.text.x = element_text(
            angle = 45, 
            vjust = 1, 
            size = 12, 
            hjust = 1
        )
    ) + 
    ggtitle("Effect of batch regression methods per individual")
```
```{r}
knitr::include_graphics("https://scrnaseq-course.cog.sanger.ac.uk/website/remove-conf-reads_files/figure-html/unnamed-chunk-14-1.png")
```
```{r echo=FALSE}
sessionInfo()
```
